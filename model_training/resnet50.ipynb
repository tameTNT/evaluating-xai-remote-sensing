{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fine-tuning a ResNet-50 model",
   "id": "1be8aa246f10aff7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "fc1df87c9773fca0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "\n",
    "# for when on NCC to be able to import local packages\n",
    "os.chdir(os.path.expanduser(\"~/l3_project\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import platform\n",
    "import time\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import wandb\n",
    "import safetensors.torch as st\n",
    "\n",
    "import dataset_processing.eurosat\n",
    "\n",
    "print(f'Using PyTorch {torch.__version__} on {platform.system()}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'Found {torch.cuda.get_device_name()} to use as a cuda device.')\n",
    "elif platform.system() == 'Darwin':\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Using {device} as torch device.')\n",
    "\n",
    "if platform.system() != 'Linux':\n",
    "    torch.set_num_threads(1)  # significantly speeds up data loading processes with less loading overhead\n",
    "    # see https://discuss.pytorch.org/t/pytorch-v2-high-cpu-consumption/205990 and https://discuss.pytorch.org/t/cpu-usage-far-too-high-and-training-inefficient/57228\n",
    "    print('Set number of threads to 1 as using a non-Linux machine.')"
   ],
   "id": "4b761d1d66e0c244",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np_rng = np.random.default_rng(42)\n",
    "torch.manual_seed(42)"
   ],
   "id": "75e203f9c130ea15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset_processing.core.get_dataset_root(), Path.getcwd()",
   "id": "f46d93e8c292be83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "checkpoints_path = Path.cwd() / 'checkpoints' / 'resnet50'\n",
    "checkpoints_path.mkdir(exist_ok=True)"
   ],
   "id": "8bf298494294bdd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# General ResNet-50 model",
   "id": "4723fd0033e54ca6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class FineTunedResNet50(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        \"\"\"\n",
    "        Initialise a ResNet-50 model with the final linear layer replaced to output the desired number of classes.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def freeze_layers(self, keep: int):\n",
    "        \"\"\"\n",
    "        Freeze layers (requires_grad = False) from the first input layer leaving the last `keep` layers (inc. output).\n",
    "        :param keep: Number of layers from output (inc.) to keep unfrozen.\n",
    "            e.g. keep=1 means only output layer is trainable.\n",
    "        \"\"\"\n",
    "\n",
    "        for dist_from_output, layer in enumerate(reversed(self.model.children())):\n",
    "            if dist_from_output >= keep:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def unfreeze_layers(self):\n",
    "        \"\"\"\n",
    "        Unfreeze all layers in the model.\n",
    "        \"\"\"\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def extra_repr(self):\n",
    "        \"\"\"\n",
    "        Add additional detail on number of frozen layers.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num_frozen = 0\n",
    "        frozen_layers = []\n",
    "        for layer in self.model.children():\n",
    "            for param in layer.parameters():\n",
    "                if not param.requires_grad:\n",
    "                    num_frozen += 1\n",
    "                    frozen_layers.append(layer)\n",
    "                    break\n",
    "\n",
    "        return f\"> {num_frozen} layers frozen: {', '.join([layer.__class__.__name__ for layer in frozen_layers])} <\""
   ],
   "id": "53f278be4eb9930c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torchvision.models.ResNet50_Weights.transforms",
   "id": "a83af629815d4f61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EuroSAT dataset",
   "id": "634f2ddb95a1a74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load dataset",
   "id": "e03d6dc752f46ca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_transforms = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=False),  # scaling handles by normalise below\n",
    "    dataset_processing.core.RSNormaliseTransform(),  # normalise to [0, 1] (based on 1st and 99th percentiles)\n",
    "    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], inplace=True),  # shift to mean 0 and std 1\n",
    "\n",
    "    # scale as expected by ResNet (see https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.ResNet50_Weights)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "    transforms.Resize(224, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "])\n",
    "wrapped_base_transforms = dataset_processing.core.tensor_dict_transform_wrapper(base_transforms)\n",
    "\n",
    "training_transforms = transforms.Compose([\n",
    "    base_transforms,\n",
    "    # Randomised transforms:\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomAffine(0, shear=0.2),  # Shear with range 0.2\n",
    "    # transforms.RandomAffine(0, scale=(1., 1.2)),  # Zoom in with range 0.2\n",
    "])\n",
    "wrapped_training_transforms = dataset_processing.core.tensor_dict_transform_wrapper(training_transforms)"
   ],
   "id": "c03ae3ab632f4123"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "eurosat_train_ds = dataset_processing.eurosat.get_dataset(\n",
    "    \"train\", transforms=wrapped_training_transforms, download=False\n",
    ")\n",
    "eurosat_val_ds = dataset_processing.eurosat.get_dataset(\n",
    "    \"val\", transforms=wrapped_base_transforms, download=False\n",
    ")\n",
    "\n",
    "print(f\"There are {len(eurosat_train_ds)} training samples and {len(eurosat_val_ds)} validation samples.\")\n",
    "print(\"Image dimensions and label:\", eurosat_train_ds[0][\"image\"].size(), eurosat_train_ds[0][\"label\"])"
   ],
   "id": "d522d16dbbd562ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualise some images",
   "id": "b83cf0977795241e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "random_indices = np_rng.choice(len(eurosat_train_ds), size=25, replace=False)\n",
    "plt.figure(figsize=(10, 10), tight_layout=True)\n",
    "for i, idx in enumerate(random_indices):\n",
    "    ax = plt.subplot(5, 5, i + 1)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.imshow(einops.rearrange(eurosat_train_ds[idx][\"image\"], \"c h w -> h w c\"))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "id": "bc90aeb8cd90cbd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training/Fine-tuning",
   "id": "fbc968544b2106b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    eurosat_train_ds, batch_size=32, num_workers=4, shuffle=True, drop_last=True\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    eurosat_val_ds, batch_size=32, num_workers=4, shuffle=False, drop_last=False\n",
    ")"
   ],
   "id": "cf6134cdb5efbbac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initialise model",
   "id": "958200a5112ff90d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "resnet50_model = FineTunedResNet50(num_classes=len(eurosat_train_ds.classes))\n",
    "resnet50_model.freeze_layers(1)\n",
    "print(resnet50_model)"
   ],
   "id": "d07674ee3512b4dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model_to_train = resnet50_model.to(device)",
   "id": "12030898cd727fad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Set up training criteria and optimiser",
   "id": "12b434d9b4ae5a71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "decay = 1e-6\n",
    "momentum = 0.9"
   ],
   "id": "1172ed6ec7b824ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "parameters_to_optimise = filter(lambda p: p.requires_grad, model_to_train.parameters())\n",
    "optimiser = torch.optim.SGD(\n",
    "    parameters_to_optimise, lr=learning_rate, weight_decay=decay, momentum=momentum, nesterov=True\n",
    ")"
   ],
   "id": "d2fd780ed32cf7ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Track with Weights & Biases",
   "id": "9d828f8585f2a51b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "run = wandb.init(\n",
    "    save_code=True,\n",
    "    project=\"evaluating_xAI_for_RS\",\n",
    "    name=\"\",\n",
    "    notes=\"\",\n",
    "    tags=[],\n",
    "    id=\"\",  # REMEMBER TO CHANGE\n",
    "    resume=\"never\",  # 'allow' to resume a crashed run\n",
    "    config={\n",
    "        \"dataset\": \"EuroSAT\",\n",
    "        \"transforms\": repr(training_transforms),\n",
    "        \"batch_size\": train_dataloader.batch_size,\n",
    "\n",
    "        \"model\": {\n",
    "            \"name\": model_to_train.__class__.__name__,\n",
    "            \"architecture\": repr(model_to_train),\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"optimiser\": repr(optimiser),\n",
    "            \"learning_rate\": learning_rate,\n",
    "        },\n",
    "\n",
    "        \"initialisation_time\": time.asctime()\n",
    "    }\n",
    ")"
   ],
   "id": "e6b6196fbbb8054b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training loop",
   "id": "4ef02a9731b1b26e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "training_loss_arr = np.zeros(0)\n",
    "training_acc_arr = np.zeros(0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch:03}\")\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        model_to_train.train()\n",
    "        images = data[\"image\"].to(device)\n",
    "        labels: torch.Tensor = data[\"label\"].to(device)\n",
    "        train_step(model_to_train, images, labels, criterion, optimiser, training_loss_arr, training_acc_arr,\n",
    "                   validation_iterator, i)\n",
    "\n",
    "    if epoch != 0 and epoch % 20 == 0:\n",
    "        st.save_model(model_to_train, f\"checkpoints/resnet50_eurosat_epoch_{epoch:03}.safetensors\",\n",
    "                      metadata={\"epoch\": str(epoch)})\n",
    "        print(f\"Model saved at epoch {epoch:03}.\")"
   ],
   "id": "fe70022acbd2b8ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "st.save_model(model_to_train, checkpoints_path / f\"{model_to_train.__class__.__name__}_final_weights.st\")",
   "id": "5b8b35a59e30d3bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Upload final model stats",
   "id": "9878ec24d5da82be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "run.summary[\"steps_trained\"]\n",
    "run.summary[\"final_loss/validation\"]\n",
    "run.summary[\"final_accuracy/validation\"]"
   ],
   "id": "50ac3bf8db8aa5e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
