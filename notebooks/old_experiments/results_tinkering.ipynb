{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "os.chdir(\"/home2/jgcw74/l3_project\")  # go to project root\n",
    "import importlib\n",
    "\n",
    "import helpers\n",
    "import dataset_processing\n",
    "import models\n",
    "import xai\n",
    "\n",
    "torch_device = helpers.utils.get_torch_device()"
   ],
   "id": "80574d4473e6ca82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import typing as t\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "be02b1ac7e036a5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "AVAILABLE_MODELS = (\"ResNet50\", \"ConvNeXtSmall\", \"SwinTransformerSmall\")",
   "id": "7031e0f183299770"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load in results",
   "id": "f24957d8944ed9e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dfs = dict()\n",
    "for explainer_name in t.get_args(xai.EXPLAINER_NAMES):\n",
    "    results_for_exp = dict()\n",
    "    h5_output_path = helpers.env_var.get_project_root() / \"results\" / explainer_name / \"evaluation_output.h5\"\n",
    "    store = pd.HDFStore(str(h5_output_path), mode=\"r\")\n",
    "    for key_name in store.keys():\n",
    "        table_name = key_name.strip(\"/\")\n",
    "        df: pd.DataFrame = store[table_name]\n",
    "        if df.isna().sum().sum() != 0:\n",
    "            raise RuntimeError(\"A results table contains NaN values!\")\n",
    "        else:\n",
    "            # adjust value in line with methodology formula\n",
    "            df[\"output_completeness : preservation_check_conf_drop\"] = 1 - df[\"output_completeness : preservation_check_conf_drop\"]\n",
    "\n",
    "            results_for_exp[table_name] = df\n",
    "    dfs[explainer_name] = results_for_exp\n",
    "    store.close()\n",
    "for key in dfs.keys():\n",
    "    print(f\"{key}: {len(dfs[key])} tables loaded\")"
   ],
   "id": "c283176dee94efed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Export results to excel and make one mega tidied-up dataframe",
   "id": "12e4faeae3bc09d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ew = pd.ExcelWriter(\"all_results_export.xlsx\")\n",
    "big_df_dict = dict()\n",
    "for sheet_name, df_dict in dfs.items():\n",
    "    temp_df = pd.concat(df_dict).reset_index()\n",
    "    temp_df[\"dataset\"] = temp_df[\"level_0\"].str.split(\"_\").str.get(0)\n",
    "    temp_df[\"model\"] = temp_df[\"level_0\"].str.split(\"_\").str.get(1)\n",
    "    temp_df = temp_df.rename(columns={\"level_1\": \"class_label\"}).set_index([\"dataset\", \"model\", \"class_label\"]).drop([\"level_0\"], axis=\"columns\")\n",
    "\n",
    "    temp_df.to_excel(ew, sheet_name=sheet_name, index=True, merge_cells=False)\n",
    "\n",
    "    big_df_dict[sheet_name] = temp_df\n",
    "ew.close()"
   ],
   "id": "d06fa94fb2873ab1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Clean up dataframe into desired multiindex format",
   "id": "285bb8755cbbaa2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "xai_ds_m_c_df = pd.concat(big_df_dict.values(), keys=big_df_dict.keys(), names=[\"xai_method\"])\n",
    "xai_ds_m_c_df = xai_ds_m_c_df.drop(\n",
    "    columns=xai_ds_m_c_df.columns[xai_ds_m_c_df.columns.str.startswith(\"continuity\") | xai_ds_m_c_df.columns.str.endswith(\"l2_distance\")]\n",
    ")\n",
    "xai_ds_m_c_df.columns = xai_ds_m_c_df.columns.str.replace(\"randomised_model_similarity\", \"random_sim\").str.replace(\"adversarial_attack_similarity\", \"adv_attk_sim\").str.replace(\"correctness\", \"COR\").str.replace(\"output_completeness\", \"O-C\").str.replace(\"contrastivity\", \"CON\").str.replace(\"compactness\", \"COM\").str.replace(\"spearman_rank\", \"SR\").str.replace(\"top_k_intersection\", \"top_m\").str.replace(\"structural_similarity\", \"ssim\")\n",
    "xai_ds_m_c_df = xai_ds_m_c_df.replace(-np.inf, np.nan)\n",
    "xai_ds_m_c_df.columns, xai_ds_m_c_df.index[-1]"
   ],
   "id": "13f6eee9d4e1890d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pd.options.display.precision = 5\n",
    "pd.options.display.max_colwidth = 20\n",
    "print(xai_ds_m_c_df.loc[(\"PartitionSHAP\", \"EuroSATMS\", \"ConvNeXtSmall\")])"
   ],
   "id": "eb2fdd32fca82ef8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Try loading some data",
   "id": "88a56d06e9089066"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_dataset_and_model(dataset_n, model_n):\n",
    "    model_type = models.get_model_type(model_n)\n",
    "    ds = dataset_processing.get_dataset_object(dataset_n, \"test\", model_type.expected_input_dim, 32, 4, torch_device)\n",
    "\n",
    "    m = model_type(False, ds.N_BANDS, ds.N_CLASSES).to(torch_device)\n",
    "    weights_path = json.load(Path(\"weights_paths.json\").open(\"r\"))[dataset_n][model_n]\n",
    "    m.load_weights(Path(\"checkpoints\") / dataset_n / model_n / weights_path)\n",
    "\n",
    "    return ds, m"
   ],
   "id": "2d2e923265d992a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_name = \"SwinTransformerSmall\"\n",
    "dataset_name = \"PatternNet\"\n",
    "\n",
    "dataset, model = get_dataset_and_model(dataset_name, model_name)\n",
    "\n",
    "print(list(enumerate(dataset.classes)))"
   ],
   "id": "4d0750222b5c1f11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class_idx = 1\n",
    "batch_num = 0\n",
    "base_exp = xai.get_explainer_object(\n",
    "    \"PartitionSHAP\", model,\n",
    "    extra_path=Path(dataset_name) / f\"c{class_idx:02}\" / f\"b{batch_num:03}\",\n",
    ")\n",
    "base_exp.force_load()"
   ],
   "id": "de2cdaad90f8d460"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "helpers.plotting.visualise_importance(base_exp.input.numpy(force=True), base_exp.explanation, alpha=0.6, with_colorbar=True)",
   "id": "dd617ec65ba52b9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "base_exp.explanation.reshape(base_exp.explanation.shape[0], -1).sum(1)",
   "id": "edfbfd7274847f0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "helpers.plotting.visualise_importance(base_exp.input.numpy(force=True), base_exp.ranked_explanation, alpha=0.4, with_colorbar=True)",
   "id": "8cd6c7c3bdf1879"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "img_dict = np.load(helpers.env_var.get_xai_output_root() /\n",
    "                   Path(dataset_name) / f\"c{class_idx:02}\" / \"combined\" /\n",
    "                   f\"{model_name}_adversarial_examples.npz\")\n",
    "og_imgs = img_dict[\"original_imgs\"]\n",
    "adv_imgs = img_dict[\"clipped_adv_imgs\"]\n",
    "helpers.plotting.show_image(\n",
    "    np.stack([np.hstack([im1, -np.ones((3, 10, im1.shape[-1])), im2]) for im1, im2 in zip(og_imgs, adv_imgs)]),\n",
    "    padding=20,\n",
    ")"
   ],
   "id": "90c7280e915d3183"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Adversarial images really are indistinguishable...",
   "id": "5c50cf72ed5c10ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.imshow(np.hstack(og_imgs[:8] - adv_imgs[:8]).transpose(1,2,0)*50 + 1/2)",
   "id": "b81773b144267314"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "base_exp.model(torch.from_numpy(og_imgs).to(torch_device)).argmax(1)",
   "id": "e3159a979ffc86fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "base_exp.model(torch.from_numpy(adv_imgs).to(torch_device)).argmax(1)",
   "id": "432c4abb7c3c6808"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compare generated explanations visually",
   "id": "93b7bdf30c0d1975"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Helpers functions",
   "id": "a136c001b3be28d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compare_explanations(dataset_n, model_n, class_i, batch_n, use_ranked=True):\n",
    "    ds, m = get_dataset_and_model(dataset_n, model_n)\n",
    "    print(ds.classes[class_i])\n",
    "    exp_list = []\n",
    "    for en in t.get_args(xai.EXPLAINER_NAMES):\n",
    "        exp = xai.get_explainer_object(\n",
    "            en, m, extra_path=Path(dataset_n) / f\"c{class_i:02}\" / f\"b{batch_n:03}\",\n",
    "        )\n",
    "        exp.force_load()\n",
    "        exp_list.append(exp)\n",
    "\n",
    "    helpers.plotting.visualise_importance(\n",
    "        np.concatenate([exp.input.numpy(force=True)[:8] for exp in exp_list]),\n",
    "        np.concatenate(\n",
    "            [exp.ranked_explanation[:8] if use_ranked else exp.explanation[:8] for exp in exp_list]\n",
    "        ),\n",
    "        alpha=0.5, with_colorbar=True\n",
    "    )\n",
    "    return exp_list"
   ],
   "id": "2aa1c3ee2852f71f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compare_models(dataset_n, class_i, batch_n):\n",
    "    for mn in AVAILABLE_MODELS:\n",
    "        exp_list = compare_explanations(dataset_n, mn, class_i, batch_n)\n",
    "        plt.title(mn)\n",
    "        plt.show()\n",
    "    return exp_list"
   ],
   "id": "37539f7bbe6864d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_ds_classes(dataset_n):\n",
    "    ds, _ = get_dataset_and_model(dataset_n, \"ResNet50\")\n",
    "    return list(enumerate(ds.classes))"
   ],
   "id": "ed3d731e9f628fe4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### UCMerced",
   "id": "c6fb1d74619fb2b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset_name = \"UCMerced\"\n",
    "batch_num = 0\n",
    "print(get_ds_classes(dataset_name))"
   ],
   "id": "acbcc117657e6bbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "_ = compare_models(dataset_name, 1, batch_num)",
   "id": "4393e44dc016c16f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Line artifacts indicate the rest of the image was deemed as not important/0 (see below)",
   "id": "6ced755e92690f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_explanations(dataset_name, \"ConvNeXtSmall\", 1, batch_num, use_ranked=False)",
   "id": "5b1f13c66a89e314"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_explanations(dataset_name, \"SwinTransformerSmall\", 1, batch_num, use_ranked=False)",
   "id": "39c3be14fe052efb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "KPCA does some weird things for certain Swin Transformer images - reverse localisation.\n",
    "Other explanation methods still highlight expected regions\n",
    "\n",
    "So we expect the output-completeness and incremental deletion metrics to be worse for KPCA on SwinT"
   ],
   "id": "2e5d83343d6c88e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Investigate poor SwinT performance",
   "id": "487248d74a0dd085"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "CoIs = (\"COR : incremental\", \"O-C\")",
   "id": "8ae291610fb30d7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ucm_airplane = xai_ds_m_c_df.loc[:, \"UCMerced\", :, \"airplane\"]\n",
    "ucm_airplane"
   ],
   "id": "a5ac6a31cc9fd9f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "column_mask = [c for c in ucm_airplane.columns if c.startswith(CoIs)]\n",
    "ucm_airplane[column_mask]"
   ],
   "id": "6590a8040b8ef069"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The best score for a deletion/preservation check is 1/-1. This only appears to be successful for ConvNeXt for KPCACAM.\n",
    "\n",
    "GradCAM does a similarity poor job for all except ConvNeXt."
   ],
   "id": "764414405ec54905"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "xai_ds_m_c_df[column_mask[1:]].loc[\"PartitionSHAP\", dataset_name].groupby(\"model\").boxplot(rot=90, sharey=True, layout=(1, 3), subplots=True)",
   "id": "12eede2f1183421"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "KPCACAM is much more inconsistent than GradCAM. PartitionSHAP appears most reliable but still rarely over 0.5.",
   "id": "5d1e2e9909ff784c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "xai_ds_m_c_df[column_mask].loc[:, dataset_name, :].groupby(\"xai_method\").boxplot(rot=90, subplots=True, layout=(1, 3))",
   "id": "139c6042009519b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "xai_ds_m_c_df[column_mask[1:]].groupby(level=[\"xai_method\", \"dataset\"]).boxplot(rot=90, subplots=False)",
   "id": "7b6a38e1ee48fed6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Inspect performance on more targetable land cover classes (not objects)",
   "id": "e1ccac4ea11e0536"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_models(dataset_name, 16, batch_num)",
   "id": "bef017306002a4be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "SHAP explanations get much messier for land based concepts - not as cohesive as GradCAM methods\n",
    "\n",
    "But might be true to underlying model/unfair because of similar concepts"
   ],
   "id": "1d14472093063957"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### EuroSATRGB",
   "id": "a0e55dd21b473302"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset_name = \"EuroSATRGB\"\n",
    "get_ds_classes(dataset_name)"
   ],
   "id": "4d4b7c93bad732fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### AnnualCrop",
   "id": "163d152fba14ec9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "last_exp_list = compare_models(dataset_name, 0, batch_num)\n",
    "last_exp_list"
   ],
   "id": "30be9a1521200e4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Explanations are much less localised with EuroSAT for a general area class such as AnnualCrop",
   "id": "f3321aa26e2cdf77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "helpers.plotting.show_image(last_exp_list[-1].input[:8], padding=20)",
   "id": "a8d87acf05b47ef4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Highways and rivers",
   "id": "ec463f011da3c3a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "last_exp_list = compare_models(dataset_name, 8, batch_num)",
   "id": "c049eb4123630169"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Rivers are easier - all appear to learn the banks of the river",
   "id": "1fa4d2ec05d8b024"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "helpers.plotting.visualise_importance(last_exp_list[0].input, last_exp_list[0].explanation, alpha=0.5)",
   "id": "1b226bb7e7b256e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Raw SHAP explanations much more precise and localised",
   "id": "25650fd663f96c6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "last_exp_list = compare_models(dataset_name, 3, batch_num)",
   "id": "e602162cb0d460e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compare RGB and MS efficacy",
   "id": "c90a8ab9fe9f3d05"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plot evaluation results",
   "id": "98c16257ed52cbd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "explainer_name = \"PartitionSHAP\"\n",
    "dataset_name = \"EuroSATRGB\"\n",
    "model_name = \"ConvNeXtSmall\""
   ],
   "id": "be2ca268f58cfad5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dfs[explainer_name][f\"{dataset_name}_{model_name}\"]",
   "id": "72d656a3e5a2c0f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "935413f67a79a564"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
