import logging
# import os
from functools import partial
import platform

import einops
import numpy as np
import shap
import shap.maskers
import torch
from jaxtyping import Float
# import matplotlib.pyplot as plt

import helpers
from xai import Explainer

logger: logging.Logger = helpers.log.main_logger


class PartitionSHAP(Explainer):
    def explain(
            self,
            x: Float[torch.Tensor, "n_samples channels height width"],
            max_evals: int = 10000,
            shap_batch_size: int = 64,
            blur_size: tuple[int, int] = (128, 128),
            num_mp_processes: int = 1,
    ):
        """
        Explains the model's predictions for the given images using the PartitionSHAP
        Explainer (shap.PartitionExplainer). Requires a decent amount of VRAM for larger batch sizes.
        (approx 6GB for n_samples=5, shap_batch_size=64).
        NB: Even though PartitionSHAP generates explanations for all model outputs, only
        the model's most confident prediction (not necessarily the correct one) is saved to the explanation property.

        :param x: Normalised Tensor of images (i.e. [-1, 1]) with shape (n_samples, channels, height, width)
        :param max_evals: Maximum number of partition explainer evaluations to perform.
            Effectively controls the 'resolution' of the explanation,
            with a factor of 10 approximately doubling the resolution.
        :param shap_batch_size: Batch size for shap evaluation.
            The method does not store gradients from each evaluation, so this can be relatively high.
        :param blur_size: Size of the blur mask to use for the SHAP Partition explainer.
            This is eventually passed to cv2.blur as the kernel.
            Defaults to (128, 128) - this is suitable for 224x224 images.
        :param num_mp_processes: Number of separate processes to use for multiprocessing.
            If <= 1, no multiprocessing is used. âš ï¸ This is not yet working and provides no noticeable speedup.
        """

        super().explain(x, max_evals=max_evals, shap_batch_size=shap_batch_size,
                        blur_size=blur_size, num_mp_processes=num_mp_processes)

        np01_x = einops.rearrange((x + 1) / 2, "b c h w -> b h w c").numpy(force=True)

        blur_str = f"blur({blur_size[0]},{blur_size[1]})"
        blur_masker = shap.maskers.Image(blur_str, np01_x[0].shape)

        if num_mp_processes > 1:  # futurefix: this is not working yet?? it takes just as long as single threaded
            if platform.system() != "Linux":
                raise NotImplementedError("Multiprocessing is only supported on Linux. "
                                          "Please use num_mp_processes=1 for now.")
            else:
                # use pip's 'multiprocess' instead of 'multiprocessing' to use dill to pickle
                import multiprocess as mp

            # multiprocessing approach based on https://github.com/shap/shap/issues/77#issuecomment-2105595557
            per_process_bs = int(np.ceil(len(x) / num_mp_processes))  # calculate batch size per process
            if per_process_bs == 0:
                per_process_bs = 1  # ensure at least 1 image per process

            batch_start_idxs = range(0, len(x), per_process_bs)
            batch_end_idxs = range(per_process_bs, len(x) + per_process_bs, per_process_bs)
            num_processes = len(batch_start_idxs)
            x_arg_mp_batches = [(
                # this is a tuple of args to pass to explain_via_partition_shap
                np01_x[start_idx:end_idx], blur_masker, max_evals, shap_batch_size//num_processes,
                # each process can only use a fraction of the batch_size since sharing same GPU
                self.device, self.batch_size//num_processes, self.model, logger.name
            ) for start_idx, end_idx in zip(batch_start_idxs, batch_end_idxs)]

            logger.info(f"ðŸ™ Beginning multi-process SHAP evaluation with "
                        f"{num_processes} processes with data size at most {per_process_bs} each.")
            ctx: mp.context.SpawnContext = mp.get_context("spawn")  # use spawn to allow CUDA use for each process
            with ctx.Pool(processes=num_processes) as pool:  # use all available cores/cpus
                explainer_results: list[shap.Explanation] = pool.starmap(explain_via_partition_shap, x_arg_mp_batches)

            logger.info("ðŸ˜‡ Finished multi-process SHAP evaluation.")
            shap_values = np.concatenate([mp_result.values for mp_result in explainer_results])
        else:  # single process approach
            logger.info("ðŸ˜‡ Beginning single-process SHAP evaluation.")
            self._raw_return = explain_via_partition_shap(
                np01_x, blur_masker, max_evals, shap_batch_size,
                self.device, self.batch_size, self.model, logger.name
            )
            shap_values = self._raw_return.values

        # only save the most confident prediction (sorted to be first by outputs arg)
        # summing over the image colour/band channels (final axis of output)
        self.explanation = shap_values[..., 0].sum(-1)
        self.save_state()


# these functions are defined at the top level outside the class to allow for pickling via multiprocess(ing)
def explain_via_partition_shap(
        np01_x: np.ndarray, masker, max_evals, shap_batch_size,
        self_device, self_split_batch_size, self_model, top_logger_name
):
    # futuretodo: (alongside multiprocessing fix)
    #  this doesn't work yet? doesn't log to the main logger but to a new one
    # top_logger = logging.getLogger(top_logger_name)
    # top_logger.debug(f"ðŸ§µ New dedicated PartitionExplainer process (id={os.getpid()}) started with shap function "
    #                  f"batch size of {shap_batch_size} and model evaluation batch size of {self_split_batch_size}.")
    # print(f"ðŸ§µ New dedicated PartitionExplainer process (id={os.getpid()}) spawned "
    #       f"with x of size {len(np01_x)}, shap function batch size of {shap_batch_size} "
    #       f"and model evaluation batch size of {self_split_batch_size}.",
    #       flush=True)

    predict_fn = partial(predict_function, device=self_device, max_batch_size=self_split_batch_size, model=self_model)
    # noinspection PyTypeChecker
    explainer = shap.PartitionExplainer(predict_fn, masker)
    # noinspection PyUnresolvedReferences
    output = explainer(
        np01_x,
        silent=True,
        max_evals=max_evals,
        batch_size=shap_batch_size,
        # order from most confident prediction (left) to lowest
        outputs=shap.Explanation.argsort.flip[:1],
    )
    # print(f"ðŸ˜‡ Finished PartitionExplainer process (id={os.getpid()}) with {len(output.values)} values.",)
    return output


def predict_function(np_imgs: np.ndarray, device, max_batch_size, model):
    # helpers.plotting.show_image(np_imgs, is_01_normalised=True, padding_value=1, imgs_per_row=8)
    # plt.show()
    # Immediately undo normalisation back to original expected by model
    model_input_imgs: torch.Tensor = einops.rearrange(
        torch.from_numpy(np_imgs * 2) - 1, "b h w c -> b c h w"
    ).to(device)

    # strictly enforce max batch size in case this function is misused by shap explainer
    # don't want to risk any COM errors ðŸ˜¬
    if model_input_imgs.shape[0] > max_batch_size:
        outputs = []
        for img_batch in helpers.utils.make_device_batches(model_input_imgs, max_batch_size, device):
            batch_output: torch.Tensor = model(img_batch)
            outputs.append(batch_output)
        model_output = torch.cat(outputs, dim=0)
    else:
        model_output: torch.Tensor = model(model_input_imgs)

    return model_output.numpy(force=True)
