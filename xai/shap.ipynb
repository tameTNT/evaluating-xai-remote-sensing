{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluating SHAP",
   "id": "ff356096779c02ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports and Setup",
   "id": "d21e2348dcc250e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "# for when on NCC to be able to import local packages\n",
    "os.chdir(os.path.expanduser(\"~/l3_project\"))\n",
    "Path.cwd()"
   ],
   "id": "341f960931edeba9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import importlib\n",
    "\n",
    "import helpers\n",
    "import dataset_processing.eurosat\n",
    "\n",
    "# to reload local module changes without kernel restart\n",
    "importlib.reload(helpers.evaluate_xai)\n",
    "importlib.reload(helpers.plotting)"
   ],
   "id": "d6b0d782f9af80b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import copy\n",
    "\n",
    "from captum.attr import DeepLiftShap\n",
    "import shap\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "import foolbox\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import einops\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from safetensors.torch import load_model"
   ],
   "id": "94fe26f2a924ce4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f'Using PyTorch {torch.__version__} on {platform.system()}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'Found {torch.cuda.get_device_name()} to use as a cuda device.')\n",
    "elif platform.system() == 'Darwin':\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Using {device} as torch device.')\n",
    "\n",
    "if platform.system() != 'Linux':\n",
    "    torch.set_num_threads(1)  # significantly speeds up data loading processes with less loading overhead\n",
    "    # see https://discuss.pytorch.org/t/pytorch-v2-high-cpu-consumption/205990 and https://discuss.pytorch.org/t/cpu-usage-far-too-high-and-training-inefficient/57228\n",
    "    print('Set number of threads to 1 as using a non-Linux machine.')"
   ],
   "id": "c2da9039d705a2f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np_rng = np.random.default_rng(42)  # for reproducibility\n",
    "_ = torch.manual_seed(42)"
   ],
   "id": "4f820dd48eb583dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EuroSAT (RGB) Dataset",
   "id": "d906e7a2839d8b99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "eurosat_val_ds = dataset_processing.eurosat.get_standard_rgb(\"val\")\n",
    "\n",
    "num_eurosat_classes = len(eurosat_val_ds.classes)\n",
    "\n",
    "print(f\"There are {len(eurosat_val_ds)} validation samples.\")\n",
    "print(\"Image dimensions and label:\", eurosat_val_ds[0][\"image\"].size(), eurosat_val_ds[0][\"label\"])"
   ],
   "id": "3fd8f71f2ce8d8f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    eurosat_val_ds, batch_size=32, num_workers=4, shuffle=False, drop_last=False\n",
    ")\n",
    "validation_iterator = iter(dataset_processing.core.cycle(val_dataloader))"
   ],
   "id": "635325190fac7fb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ResNet 50",
   "id": "3ea3baf303c59bcc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Model",
   "id": "2bfceb5fe9f372a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "checkpoints_path = Path.cwd() / 'checkpoints'\n",
    "assert checkpoints_path.exists()"
   ],
   "id": "b226e79570cd781b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_resnet50_saved = list(checkpoints_path.glob('./resnet50/*.st'))\n",
    "# print(all_resnet50_saved)\n",
    "latest_resnet50_path = max(all_resnet50_saved, key=os.path.getctime)\n",
    "latest_resnet50_path"
   ],
   "id": "fed306a88ba8a7b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "resnet50 = helpers.models.FineTunedResNet50(num_classes=num_eurosat_classes).to(device)",
   "id": "3b2d9c9bc5e75e5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('Missing/Unexpected keys:', load_model(resnet50, latest_resnet50_path))\n",
    "_ = resnet50.eval()  # turn off randomisation in batchnorm layers, etc."
   ],
   "id": "9f63429055a71191"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Confirm model accuracy",
   "id": "cc41be6089d3abb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "check_acc = False\n",
    "if check_acc:\n",
    "    _, acc = helpers.ml.validation_step(\n",
    "        resnet50, nn.CrossEntropyLoss(), validation_iterator, len(val_dataloader)\n",
    "    )\n",
    "    assert acc > 0.98\n",
    "    print(\"Validation accuracy\", acc)"
   ],
   "id": "25a4510f6503482a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Select images to explain",
   "id": "937536cb48e06f9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "idxs_to_explain = np_rng.integers(0, len(eurosat_val_ds), 5)\n",
    "imgs_to_explain = torch.stack([eurosat_val_ds[i][\"image\"] for i in idxs_to_explain]).to(device)\n",
    "true_labels = [eurosat_val_ds[i][\"label\"] for i in idxs_to_explain]\n",
    "\n",
    "blurred_imgs = transforms.functional.gaussian_blur_image(imgs_to_explain, kernel_size=21, sigma=10)\n",
    "black_imgs = torch.zeros_like(imgs_to_explain) - 1\n",
    "# Black background as in https://dl.acm.org/doi/abs/10.1145/3331184.3331312\n",
    "# Blurred as in https://www.sciencedirect.com/science/article/pii/S0303243421002270"
   ],
   "id": "22bcf45f59effe88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "helpers.plotting.show_image(\n",
    "    einops.rearrange(imgs_to_explain, \"(b1 b2) c h w -> c (b1 h) (b2 w)\", b2=len(idxs_to_explain)))"
   ],
   "id": "b14845876e93edd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "preds = resnet50(imgs_to_explain)\n",
    "preds = torch.softmax(preds, dim=-1).cpu().detach().numpy()\n",
    "_, axs = plt.subplots(1, len(idxs_to_explain), figsize=(2 * len(idxs_to_explain), 2))\n",
    "for i in range(len(idxs_to_explain)):\n",
    "    ax: plt.Axes = axs[i]\n",
    "    ax.bar(eurosat_val_ds.classes, preds[i])\n",
    "    # rotate x ticks for axis\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "print(true_labels)"
   ],
   "id": "f856501fb4763355"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "random_bg_imgs = torch.stack([eurosat_val_ds[i][\"image\"] for i in np_rng.integers(0, len(eurosat_val_ds), 100)]).to(\n",
    "    device)"
   ],
   "id": "f5aded3d94cf8f49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "random_blurred_bg_imgs = transforms.functional.gaussian_blur_image(\n",
    "    random_bg_imgs, kernel_size=15, sigma=10\n",
    ").to(device)"
   ],
   "id": "3634bd746e1d49fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "helpers.plotting.show_image(\n",
    "    einops.rearrange(random_bg_imgs[:5], \"(b1 b2) c h w -> c (b1 h) (b2 w)\", b2=len(idxs_to_explain)))"
   ],
   "id": "14012df6eea8aeb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Set up/Experiment with SHAP",
   "id": "b31ab2765e92538f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Captum DeepLiftShap",
   "id": "d7147b78187a83e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "deep_shap_explainer = DeepLiftShap(resnet50, multiply_by_inputs=True)  # True for global attribution",
   "id": "3b5eba650554956e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "captum_shap_vals = helpers.xai.calculate_shap_values_tensor(imgs_to_explain, blurred_imgs, deep_shap_explainer,\n",
    "                                                            num_eurosat_classes)"
   ],
   "id": "18da0effd7bcbad2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n = 5\n",
    "shap.image_plot(\n",
    "    helpers.xai.prepare_shap_for_image_plot(captum_shap_vals[:, :n]),\n",
    "    einops.rearrange((imgs_to_explain[:n] + 1) / 2, \"b c h w -> b h w c\").cpu().numpy(),\n",
    "    labels=np.tile(eurosat_val_ds.classes, (imgs_to_explain[:n].shape[0], 1)),\n",
    "    true_labels=[eurosat_val_ds.classes[int(i)] for i in true_labels[:n]],\n",
    ")"
   ],
   "id": "1e0571e44e4b2bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Pooled SHAP values",
   "id": "f65dea65adce0067"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pool_size = 16\n",
    "pooled_captum_shap_vals = (pool_size ** 2) * nn.AvgPool2d(kernel_size=pool_size, stride=pool_size)(\n",
    "    captum_shap_vals.flatten(0, 1)\n",
    ").repeat_interleave(pool_size, dim=-2).repeat_interleave(pool_size, dim=-1)\n",
    "pooled_captum_shap_vals = torch.unflatten(pooled_captum_shap_vals, 0, (num_eurosat_classes, -1))"
   ],
   "id": "cb1738f51dc21da8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n = 5\n",
    "shap.image_plot(\n",
    "    helpers.xai.prepare_shap_for_image_plot(pooled_captum_shap_vals[:, :n]),\n",
    "    einops.rearrange((imgs_to_explain[:n] + 1) / 2, \"b c h w -> b h w c\").cpu().numpy(),\n",
    "    labels=np.tile(eurosat_val_ds.classes, (imgs_to_explain[:n].shape[0], 1)),\n",
    "    true_labels=[eurosat_val_ds.classes[int(i)] for i in true_labels[:n]],\n",
    ")"
   ],
   "id": "397eef79e7d2abd8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "captum_random_bg_shap_vals = helpers.xai.calculate_shap_values_tensor(imgs_to_explain, random_bg_imgs[:25],\n",
    "                                                                      deep_shap_explainer, num_eurosat_classes)\n",
    "\n",
    "n = 5\n",
    "shap.image_plot(\n",
    "    helpers.xai.prepare_shap_for_image_plot(captum_random_bg_shap_vals[:, :n]),\n",
    "    einops.rearrange((imgs_to_explain[:n] + 1) / 2, \"b c h w -> b h w c\").cpu().numpy(),\n",
    "    labels=np.tile(eurosat_val_ds.classes, (imgs_to_explain[:n].shape[0], 1)),\n",
    "    true_labels=[eurosat_val_ds.classes[int(i)] for i in true_labels[:n]],\n",
    "    hspace=0.3,\n",
    ")"
   ],
   "id": "5aa5e2c3e8d50ff9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Original SHAP library",
   "id": "225b91de7ab0b29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_fn(np_imgs: np.ndarray):\n",
    "    model_input_img = einops.rearrange(torch.from_numpy(np_imgs * 2) - 1, \"b h w c -> b c h w\").to(device)\n",
    "    model_output: torch.Tensor = resnet50(model_input_img)\n",
    "    # softmax_output = torch.softmax(model_output, dim=-1)\n",
    "    return model_output.cpu().detach().numpy()"
   ],
   "id": "78049c236b03c4f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np01_imgs_to_explain = einops.rearrange((imgs_to_explain + 1) / 2, \"b c h w -> b h w c\").cpu().numpy()",
   "id": "7ad0109f9f15b498"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Partition Explainer\n",
    "\n",
    "Following regime in https://shap.readthedocs.io/en/latest/example_notebooks/image_examples/image_classification/Explain%20MobilenetV2%20using%20the%20Partition%20explainer%20%28PyTorch%29.html"
   ],
   "id": "ffc04d741b0f6205"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "blur_masker = shap.maskers.Image(\"blur(128,128)\", np01_imgs_to_explain[0].shape)\n",
    "partition_explainer = shap.PartitionExplainer(predict_fn, blur_masker, output_names=eurosat_val_ds.classes)"
   ],
   "id": "cf9de503ea0c57b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "partition_shap_vals = partition_explainer(\n",
    "    np01_imgs_to_explain,\n",
    "    max_evals=10000,\n",
    "    batch_size=128,\n",
    "    outputs=shap.Explanation.argsort.flip,  # order from most confident prediction (left) to lowest\n",
    ")"
   ],
   "id": "bdc0c3d11fc9a7b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shap.image_plot(\n",
    "    shap_values=[val for val in np.moveaxis(partition_shap_vals.values, -1, 0)],\n",
    "    pixel_values=((partition_shap_vals.data + 1) / 2),\n",
    "    labels=np.vectorize(lambda x: x[:5])(partition_shap_vals.output_names),\n",
    "    true_labels=[f'{eurosat_val_ds.classes[int(i)][:5]}' for i in true_labels],\n",
    "    show=False,\n",
    ")\n",
    "_ = plt.gcf().suptitle(f\"{partition_explainer.__class__.__name__} - {blur_masker.mask_value}\")"
   ],
   "id": "1c4f5d321f8ea5d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Using 0 masker",
   "id": "36ec2242c79c6073"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "masker = shap.maskers.Image(0, np01_imgs_to_explain[0].shape)  # fill with zeros rather than blurring\n",
    "partition0_explainer = shap.PartitionExplainer(predict_fn, masker, output_names=eurosat_val_ds.classes)\n",
    "partition0_shap_vals = partition0_explainer(\n",
    "    np01_imgs_to_explain[:2],\n",
    "    max_evals=10000,\n",
    "    batch_size=128,\n",
    "    outputs=shap.Explanation.argsort.flip,  # order from most confident prediction (left) to lowest\n",
    ")\n",
    "shap.image_plot(\n",
    "    shap_values=[val for val in np.moveaxis(partition0_shap_vals.values, -1, 0)],\n",
    "    pixel_values=((partition0_shap_vals.data + 1) / 2),\n",
    "    labels=np.vectorize(lambda x: x[:5])(partition0_shap_vals.output_names),\n",
    "    true_labels=[f'{eurosat_val_ds.classes[int(i)][:5]}' for i in true_labels[:2]],\n",
    "    show=False,\n",
    ")\n",
    "_ = plt.gcf().suptitle(f\"{partition_explainer.__class__.__name__} - {masker.mask_value}\")"
   ],
   "id": "9c3c5268600ac743"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Deep Explainer (broken?)\n",
    "\n",
    "Following regime in https://shap.readthedocs.io/en/latest/example_notebooks/image_examples/image_classification/PyTorch%20Deep%20Explainer%20MNIST%20example.html"
   ],
   "id": "c4aaeb53d6d7bfac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "deep_explainer = shap.DeepExplainer(resnet50, random_bg_imgs[:50])",
   "id": "203a16a12e04c761"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Requires a lot of GPU memory - 50 background images requires 17.3GB of GPU memory/VRAM",
   "id": "acac248d53beff44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# additivity check fails - implementation bug on my or shap's end...?\n",
    "deep_shap_vals = deep_explainer.shap_values(imgs_to_explain[:2], check_additivity=False)\n",
    "deep_shap_vals = einops.rearrange(deep_shap_vals, \"b c h w l -> l b c h w\")"
   ],
   "id": "fdd0f1fc9fb10317"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shap.image_plot(\n",
    "    list(einops.rearrange(deep_shap_vals, \"l b c h w -> l b h w c\")),\n",
    "    pixel_values=einops.rearrange((imgs_to_explain[:2] + 1) / 2, \"b c h w -> b h w c\").cpu().numpy(),\n",
    "    labels=(np.tile([x[:5] for x in eurosat_val_ds.classes], (imgs_to_explain[:2].shape[0], 1))),\n",
    "    true_labels=[f'{eurosat_val_ds.classes[int(i)][:5]}' for i in true_labels[:2]],\n",
    "    show=True,\n",
    ")"
   ],
   "id": "a0a50557172f5e34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pool_size = 16\n",
    "pooled_deep_shap_vals = (pool_size ** 2) * nn.AvgPool2d(kernel_size=pool_size, stride=pool_size)(\n",
    "    torch.from_numpy(deep_shap_vals).flatten(0, 1)).repeat_interleave(pool_size, dim=-2).repeat_interleave(pool_size,\n",
    "                                                                                                           dim=-1)\n",
    "pooled_deep_shap_vals = torch.unflatten(pooled_deep_shap_vals, 0, (num_eurosat_classes, -1))"
   ],
   "id": "65751bfcc8f2691d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shap.image_plot(\n",
    "    list(einops.rearrange(pooled_deep_shap_vals, \"l b c h w -> l b h w c\")),\n",
    "    pixel_values=einops.rearrange((imgs_to_explain[:2] + 1) / 2, \"b c h w -> b h w c\").cpu().numpy(),\n",
    "    labels=(np.tile([x[:5] for x in eurosat_val_ds.classes], (imgs_to_explain[:2].shape[0], 1))),\n",
    "    true_labels=[f'{eurosat_val_ds.classes[int(i)][:5]}' for i in true_labels[:2]],\n",
    "    show=True,\n",
    ")"
   ],
   "id": "d25fab84c8821aeb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Trying to debug the additivity of DeepExplainer...",
   "id": "53ed9a67b77b2700"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ResNet50Wrapper(nn.Module):\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model.eval()\n",
    "        self.output = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(self.model(x))\n",
    "\n",
    "\n",
    "wrapped_resnet50 = ResNet50Wrapper(resnet50)"
   ],
   "id": "e89e9f1c2ed33404"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "e = shap.DeepExplainer(wrapped_resnet50, random_bg_imgs[:50])\n",
    "# s = e.shap_values(imgs_to_explain[:2], check_additivity=True)"
   ],
   "id": "3e0dddb9c67dc120"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "imgs_to_explain.min(), imgs_to_explain.max(), random_bg_imgs.min(), random_bg_imgs.max()",
   "id": "baf35dc1af80d10f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Use a simpler model for testing\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(16 * 224 * 224, num_eurosat_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "simple_model = SimpleModel().to(device)\n",
    "\n",
    "e = shap.DeepExplainer(simple_model, random_bg_imgs[:50])\n",
    "# s = e.shap_values(imgs_to_explain[:2], check_additivity=True)"
   ],
   "id": "edba4451e846faf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate SHAP",
   "id": "9b12739063ea8733"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "randomised_model = copy.deepcopy(resnet50).to(device)\n",
    "helpers.evaluate_xai.reset_child_params(randomised_model)\n",
    "_ = randomised_model.eval()"
   ],
   "id": "a4e5f64885bffdfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if check_acc:\n",
    "    _, og_acc = helpers.ml.validation_step(\n",
    "        resnet50, nn.CrossEntropyLoss(), validation_iterator, len(val_dataloader)\n",
    "    )\n",
    "    _, random_acc = helpers.ml.validation_step(\n",
    "        randomised_model, nn.CrossEntropyLoss(), validation_iterator, len(val_dataloader)\n",
    "    )\n",
    "    print(f\"Original/Randomised accuracy on validation set: {og_acc:.4f}/{random_acc:.4f}\")"
   ],
   "id": "77d4fc43004f93c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Calculate Final Values",
   "id": "694e2fc4b07597f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### Calculate Captum SHAP values\n",
    "\n",
    "⚠️ Requires ~18GB of GPU memory (VRAM)"
   ],
   "id": "6e8957b8d27abd0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "og_shap_e = DeepLiftShap(resnet50, multiply_by_inputs=True)\n",
    "random_shap_e = DeepLiftShap(randomised_model, multiply_by_inputs=True)"
   ],
   "id": "84556271ada5498e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "og_shap_values = helpers.xai.calculate_shap_values_tensor(imgs_to_explain, blurred_imgs, og_shap_e, num_eurosat_classes)\n",
    "random_shap_values = helpers.xai.calculate_shap_values_tensor(imgs_to_explain, blurred_imgs, random_shap_e,\n",
    "                                                              num_eurosat_classes)"
   ],
   "id": "642782436795c2ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n = 5\n",
    "shap.image_plot(\n",
    "    helpers.xai.prepare_shap_for_image_plot(og_shap_values[:, :n]),\n",
    "    einops.rearrange((imgs_to_explain[:n] + 1) / 2, \"b c h w -> b h w c\").cpu().numpy(),\n",
    "    labels=np.tile(eurosat_val_ds.classes, (imgs_to_explain[:n].shape[0], 1)),\n",
    "    true_labels=[eurosat_val_ds.classes[int(i)] for i in true_labels[:n]],\n",
    ")"
   ],
   "id": "82e400fcc0cd6df8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n = 5\n",
    "shap.image_plot(\n",
    "    helpers.xai.prepare_shap_for_image_plot(random_shap_values[:, :n]),\n",
    "    einops.rearrange((imgs_to_explain[:n] + 1) / 2, \"b c h w -> b h w c\").cpu().numpy(),\n",
    "    labels=np.tile(eurosat_val_ds.classes, (imgs_to_explain[:n].shape[0], 1)),\n",
    "    true_labels=[eurosat_val_ds.classes[int(i)] for i in true_labels[:n]],\n",
    ")"
   ],
   "id": "704c0e1a9b2c9b7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Calculate Partition SHAP values\n",
   "id": "9df3f80ed1aaa8a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from functools import partial",
   "id": "61809aed35e8930"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np01_imgs_to_explain = einops.rearrange((imgs_to_explain + 1) / 2, \"b c h w -> b h w c\").cpu().numpy()",
   "id": "3618b72a9e908da3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_fn(np_imgs: np.ndarray, model: nn.Module = None):\n",
    "    model_input_img = einops.rearrange(torch.from_numpy(np_imgs * 2) - 1, \"b h w c -> b c h w\").to(device)\n",
    "    model_output: torch.Tensor = model(model_input_img)\n",
    "    # softmax_output = torch.softmax(model_output, dim=-1)\n",
    "    return model_output.cpu().detach().numpy()"
   ],
   "id": "acf2d228d9813653"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "blur_masker = shap.maskers.Image(\"blur(128,128)\", np01_imgs_to_explain[0].shape)\n",
    "og_partition_e = shap.PartitionExplainer(partial(predict_fn, model=resnet50), blur_masker,\n",
    "                                         output_names=eurosat_val_ds.classes)"
   ],
   "id": "6cfd39277a23a525"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "random_partition_e = shap.PartitionExplainer(partial(predict_fn, model=randomised_model), blur_masker,\n",
    "                                             output_names=eurosat_val_ds.classes)"
   ],
   "id": "ce739341a41312f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "⚠️ Also requires a lot of memory for high batch sizes!\n",
    "\n",
    "For `max_evals=10000` and `batch_size=64`, requires approx 6GB."
   ],
   "id": "e6a49f2094376321"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "partition_og_shap = og_partition_e(\n",
    "    np01_imgs_to_explain,\n",
    "    max_evals=10000,\n",
    "    batch_size=64,  # batch_size=5 takes 4m 21s/=32 takes 3m40s/=64 takes 3m34s\n",
    "    # outputs=shap.Explanation.argsort.flip,  # order from most confident prediction (left) to lowest\n",
    ")\n",
    "partition_random_shap = random_partition_e(\n",
    "    np01_imgs_to_explain,\n",
    "    max_evals=10000,\n",
    "    batch_size=64,\n",
    "    # outputs=shap.Explanation.argsort.flip,  # order from most confident prediction (left) to lowest\n",
    ")"
   ],
   "id": "87347d6111ee2057"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shap.image_plot(\n",
    "    shap_values=[val for val in np.moveaxis(partition_og_shap.values, -1, 0)],\n",
    "    pixel_values=((partition_og_shap.data + 1) / 2),\n",
    "    labels=np.tile([x[:5] for x in eurosat_val_ds.classes], (imgs_to_explain.shape[0], 1)),\n",
    "    true_labels=[f'{eurosat_val_ds.classes[int(i)][:5]}' for i in true_labels],\n",
    "    hspace=\"auto\",\n",
    "    show=False,\n",
    ")\n",
    "# _ = plt.gcf().suptitle(f\"{og_partition_e.__class__.__name__} - {blur_masker.mask_value}\")"
   ],
   "id": "87ebfdf956141801"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shap.image_plot(\n",
    "    shap_values=[val for val in np.moveaxis(partition_random_shap.values, -1, 0)],\n",
    "    pixel_values=((partition_random_shap.data + 1) / 2),\n",
    "    labels=np.tile([x[:5] for x in eurosat_val_ds.classes], (imgs_to_explain.shape[0], 1)),\n",
    "    true_labels=[f'{eurosat_val_ds.classes[int(i)][:5]}' for i in true_labels],\n",
    "    hspace=\"auto\",\n",
    "    show=False,\n",
    ")\n",
    "# _ = plt.gcf().suptitle(f\"{random_partition_e.__class__.__name__} - {blur_masker.mask_value}\")"
   ],
   "id": "85c231eb5cc65e7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Save/Load SHAP values",
   "id": "ab20ce8b3838e12a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "output_path = Path.cwd() / \"output\"",
   "id": "eb1a9bdef2006f18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# partition_og_shap_values = partition_og_shap.values\n",
    "# partition_random_shap_values = partition_random_shap.values\n",
    "# if isinstance(og_shap_values, torch.Tensor):\n",
    "#     og_shap_values = og_shap_values.cpu()\n",
    "#     random_shap_values = random_shap_values.cpu()\n",
    "#\n",
    "# np.savez_compressed(output_path / \"resnet50_shap_vals.npz\",\n",
    "#                     og_shap_values=og_shap_values,\n",
    "#                     random_shap_values=random_shap_values,\n",
    "#                     partition_og_shap_values=partition_og_shap_values,\n",
    "#                     partition_random_shap_values=partition_random_shap_values)"
   ],
   "id": "8c8a49f0c31fbf96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with np.load(output_path / \"resnet50_shap_vals.npz\") as data:\n",
    "    og_shap_values = data[\"og_shap_values\"]\n",
    "    random_shap_values = data[\"random_shap_values\"]\n",
    "    partition_og_shap_values = data[\"partition_og_shap_values\"]\n",
    "    partition_random_shap_values = data[\"partition_random_shap_values\"]"
   ],
   "id": "bb070944efe33155"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Correctness: Parameter Randomisation",
   "id": "ca2b2168dfd4f5ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Calculate Difference (the actual evaluation)",
   "id": "3e46264c49ffcb92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(eurosat_val_ds.classes)",
   "id": "1c1f8cc1e0d7afd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# partition_og_shap_values.values.shape, np.array(helpers.xai.prepare_shap_for_image_plot(og_shap_values)).transpose(1, 0, 2, 3, 4).shape",
   "id": "d166861860cca1df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "s1 = einops.rearrange(og_shap_values, \"l b c h w -> b h w c l\")\n",
    "s2 = einops.rearrange(random_shap_values, \"l b c h w -> b h w c l\")\n",
    "\n",
    "helpers.similarity_metrics.pixel_l2_distance_per_label(s1, s2)"
   ],
   "id": "2e556c921d81344b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "randomised_l2_df = helpers.similarity_metrics.make_l2_distance_per_label_df(\n",
    "    eurosat_val_ds.classes, partition_og_shap_values, partition_random_shap_values, normalise=True)\n",
    "randomised_l2_df"
   ],
   "id": "e4899d31e337aa41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "randomised_l2_df.plot(kind=\"bar\", xlabel=\"class\", ylabel=\"L2 distance\",\n",
    "                      title=\"L2 distance between randomised and true model's shap values\")"
   ],
   "id": "37c83a5446a3df7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Correctness: Incremental Deletion",
   "id": "fabac7f1d5be751a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "partition_shap_vals = einops.rearrange(partition_og_shap_values, \"b h w c l -> b l h w c\")\n",
    "partition_shap_vals.shape"
   ],
   "id": "c015ed6ed2c8690b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "shap_importance_rank = helpers.utils.rank_pixel_importance(partition_shap_vals.sum(-1))",
   "id": "3cd9dd2a03663345"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "i = 4  # selected image for testing\n",
    "true_label_text = eurosat_val_ds.classes[int(true_labels[i])]\n",
    "helpers.plotting.visualise_importance(\n",
    "    imgs_to_explain[i], shap_importance_rank[i][int(true_labels[i])]\n",
    ")\n",
    "plt.show()"
   ],
   "id": "77e2cb2047ea1b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Deletion/Infilling",
   "id": "653275e52acef4f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### By importance",
   "id": "bacc9977899687e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_del_iterations = 30\n",
    "iterative_deletions, k_values = helpers.evaluate_xai.incrementally_delete(imgs_to_explain[i].cpu().numpy(),\n",
    "                                                                          shap_importance_rank[i][int(true_labels[i])],\n",
    "                                                                          num_del_iterations,\n",
    "                                                                          \"shuffle\")  # Nearest neighbour deletion as in I. Kakogeorgiou and K. Karantzalos\n",
    "iterative_deletions = np.squeeze(\n",
    "    iterative_deletions)  # remove singleton dim (there is only 1 trial when importance_rank is specified)\n",
    "helpers.plotting.show_image(einops.rearrange(iterative_deletions[::5], \"p c h w -> c h (p w)\"))\n",
    "plt.show()\n",
    "# helpers.plotting.show_image(einops.rearrange(iterative_deletions[-3:], \"p c h w -> c h (p w)\"))\n",
    "# plt.show()"
   ],
   "id": "142e0555b8e30de8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = helpers.evaluate_xai.make_preds_df(resnet50, iterative_deletions, columns=eurosat_val_ds.classes, max_batch_size=4)",
   "id": "7f81c54e815f98aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# df.plot(kind=\"bar\", stacked=False, grid=True, rot=45, figsize=(15, 5),\n",
    "#         title=\"Change in predictions with incremental deletion\")\n",
    "df.plot(kind=\"line\", xlabel=\"iterations\", rot=45, xlim=(0, num_del_iterations),\n",
    "        y=true_label_text,\n",
    "        ylabel=\"confidence\", ylim=(0, 1),\n",
    "        grid=True,\n",
    "        title=\"Effect of deletions on correct class prediction confidence\")"
   ],
   "id": "76d2a8eb5c41ad49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Randomised",
   "id": "b9cfd28fd0618e69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_rand_trials = 10\n",
    "random_deletions, k_values = helpers.evaluate_xai.incrementally_delete(imgs_to_explain[i].cpu().numpy(),\n",
    "                                                                       (16, None, num_rand_trials),\n",
    "                                                                       num_del_iterations, \"nn\")\n",
    "\n",
    "helpers.plotting.show_image(einops.rearrange(random_deletions[::5, 0], \"p c h w -> c h (p w)\"))"
   ],
   "id": "925186b01bfa74ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "flatted_random_deletions = random_deletions.reshape(-1, *random_deletions.shape[2:])  # combine iterations and trials\n",
    "flatted_random_deletions.shape"
   ],
   "id": "27595819c1c6338b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rand_df = helpers.evaluate_xai.make_preds_df(resnet50, flatted_random_deletions, columns=eurosat_val_ds.classes,\n",
    "                                             max_batch_size=5)\n",
    "rand_df = rand_df.groupby(np.arange(len(rand_df)) // num_rand_trials).mean()"
   ],
   "id": "1c9da7e76020b59a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Area under curve calculation",
   "id": "91cb06dba7c9de42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "importlib.reload(helpers.plotting)\n",
    "helpers.plotting.make_deletions_plot(df, rand_df, return_aucs=True,\n",
    "                                     method_names=[\"cam\", \"random\"], plot_class=true_label_text,\n",
    "                                     plt_title=\"Effect of deletions on confidence of correct class prediction\")"
   ],
   "id": "eedb726b6ad75670"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Output-completeness\n",
    "Preservation/Deletion check"
   ],
   "id": "88463f0f2430621f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "deletion_threshold = 0.1  # \"All important features\"\n",
    "img = imgs_to_explain[i].cpu().numpy()\n",
    "num_pixels = img.shape[-2] * img.shape[-1]"
   ],
   "id": "525f94a0259a5502"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Deletion",
   "id": "f769c1e0cdb4d462"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "deleted = helpers.evaluate_xai.delete_top_k_important(img, shap_importance_rank[i][int(true_labels[i])],\n",
    "                                                      deletion_threshold * num_pixels, \"nn\")\n",
    "helpers.plotting.show_image(deleted)"
   ],
   "id": "768dcde38a03faa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "random_deleted_images = []\n",
    "for _ in range(num_rand_trials):\n",
    "    random_deleted_images.append(\n",
    "        helpers.evaluate_xai.delete_top_k_important(img, (16, np_rng), deletion_threshold * num_pixels, \"nn\")\n",
    "    )\n",
    "random_deleted_images = np.array(random_deleted_images)\n",
    "# helpers.plotting.show_image(deleted)"
   ],
   "id": "9127210a6d519a0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "importlib.reload(helpers.evaluate_xai)\n",
    "random_deletion_check_df = helpers.evaluate_xai.make_preds_df(\n",
    "    resnet50, random_deleted_images, columns=eurosat_val_ds.classes, max_batch_size=5\n",
    ")\n",
    "random_deletion_acc = random_deletion_check_df[true_label_text].mean()\n",
    "random_deletion_acc"
   ],
   "id": "64de60c03800e49d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "org_acc, del_acc = resnet50(\n",
    "    torch.from_numpy(np.stack([img, deleted])).to(device)\n",
    ").detach().cpu().softmax(-1)[:, int(true_labels[i])]\n",
    "org_acc, del_acc"
   ],
   "id": "a37ec9cf5b5b3cb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# drop in acc vs random = (rand_del_acc - org_acc) - (del_acc - org_acc) = rand_del_acc - del_acc\n",
    "print(\"Deletion check (↑, 1 best):\",\n",
    "      random_deletion_acc - del_acc.item())  # we want del_acc to be low for a good explanation"
   ],
   "id": "fa04044d621b95f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Preservation (inverse of deletion)",
   "id": "604d0790e2d82bb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inverted_rank = helpers.utils.rank_pixel_importance(shap_importance_rank[i][int(true_labels[i])])\n",
    "preserved = helpers.evaluate_xai.delete_top_k_important(img, inverted_rank, (1 - deletion_threshold) * num_pixels, \"nn\")\n",
    "helpers.plotting.show_image(preserved)"
   ],
   "id": "efd2b5b9c97fbc96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "random_preserved_images = []\n",
    "for _ in range(num_rand_trials):\n",
    "    random_preserved_images.append(\n",
    "        helpers.evaluate_xai.delete_top_k_important(img, (16, np_rng), (1 - deletion_threshold) * num_pixels, \"nn\")\n",
    "    )\n",
    "random_preserved_images = np.array(random_preserved_images)\n",
    "# helpers.plotting.show_image(random_preserved_images[0])"
   ],
   "id": "8166c0e27fa201d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "random_preservation_check_df = helpers.evaluate_xai.make_preds_df(\n",
    "    resnet50, random_preserved_images, columns=eurosat_val_ds.classes, max_batch_size=5\n",
    ")\n",
    "random_preservation_acc = random_preservation_check_df[true_label_text].mean()\n",
    "random_preservation_acc"
   ],
   "id": "10db6690cdbf7fe8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "org_acc, pres_acc = resnet50(\n",
    "    torch.from_numpy(np.stack([img, preserved])).to(device)\n",
    ").detach().cpu().softmax(-1)[:, int(true_labels[i])]\n",
    "org_acc, pres_acc"
   ],
   "id": "ecb7d02d1060f974"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# drop in acc vs random = 1 + (rand_pres_acc - org_acc) - (pres_acc - org_acc) = 1 + rand_pres_acc - pres_acc\n",
    "print(\"Preservation check (↓, 0 best):\",\n",
    "      1 + random_preservation_acc - pres_acc.item())  # we want pres_acc to be high for a good explanation"
   ],
   "id": "7d1cb5096df21931"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Continuity: Perturbation sensitivity",
   "id": "3ccac3aa3d97a267"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Add noise and check pred impact",
   "id": "9baff636aff57fec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "perturb_degree = 0.15",
   "id": "4134336f249618db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "noisy_samples = helpers.evaluate_xai.perturb(imgs_to_explain, perturb_degree)\n",
    "\n",
    "helpers.plotting.show_image(noisy_samples)"
   ],
   "id": "2f34e2da38f943c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Generate new explanations on perturbed images",
   "id": "3cd3f2b960fcb1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np01_noisy_samples = einops.rearrange((noisy_samples + 1) / 2, \"b c h w -> b h w c\").cpu().numpy()\n",
    "partition_og_shap_noisy_samples = og_partition_e(\n",
    "    np01_noisy_samples,\n",
    "    max_evals=10000,\n",
    "    batch_size=64,\n",
    ")"
   ],
   "id": "bde0e69a57359efa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# partition_og_shap_noisy_samples_values = partition_og_shap_noisy_samples.values\n",
    "# np.savez_compressed(output_path / f\"resnet50_noisy{perturb_degree:.2f}_shap_vals.npz\",\n",
    "#                     partition_og_shap_noisy_samples_values=partition_og_shap_noisy_samples_values,\n",
    "#                     images=np01_noisy_samples,\n",
    "#                     )"
   ],
   "id": "2b7d560052e90abd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with np.load(output_path / f\"resnet50_noisy{perturb_degree:.2f}_shap_vals.npz\") as data:\n",
    "    partition_og_shap_noisy_samples_values = data[\"partition_og_shap_noisy_samples_values\"]\n",
    "    np01_noisy_samples = data[\"images\"]\n",
    "    noisy_samples = torch.from_numpy(einops.rearrange((np01_noisy_samples * 2) - 1, \"b h w c -> b c h w\"))\n",
    "\n",
    "helpers.plotting.show_image(np01_noisy_samples)"
   ],
   "id": "df1bb37f2aadcd2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pred_change_df = helpers.evaluate_xai.pred_change_df(resnet50, imgs_to_explain, noisy_samples, 5)\n",
    "pred_change_df"
   ],
   "id": "7262c54f6ee0fbad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "same_idxs = pred_change_df.index[pred_change_df['original_pred'] == pred_change_df['perturbed_pred']]\n",
    "same_idxs"
   ],
   "id": "8508575cf7e9a5e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shap.image_plot(\n",
    "    shap_values=[val for val in np.moveaxis(partition_og_shap_values, -1, 0)],\n",
    "    pixel_values=((np01_imgs_to_explain + 1) / 2),\n",
    "    labels=np.tile([x[:5] for x in eurosat_val_ds.classes], (np01_imgs_to_explain.shape[0], 1)),\n",
    "    true_labels=[f'{eurosat_val_ds.classes[int(i)][:5]}' for i in true_labels],\n",
    "    hspace=\"auto\",\n",
    "    show=False,\n",
    ")\n",
    "print(\"SHAP values for original image\")"
   ],
   "id": "e7abecb1988406c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shap.image_plot(\n",
    "    shap_values=[val for val in np.moveaxis(partition_og_shap_noisy_samples_values, -1, 0)],\n",
    "    pixel_values=((np01_noisy_samples + 1) / 2),\n",
    "    labels=np.tile([x[:5] for x in eurosat_val_ds.classes], (np01_noisy_samples.shape[0], 1)),\n",
    "    true_labels=[f'{eurosat_val_ds.classes[int(i)][:5]}' for i in true_labels],\n",
    "    hspace=\"auto\",\n",
    "    show=False,\n",
    ")\n",
    "print(\"SHAP values for perturbed image\")"
   ],
   "id": "e5a6b5533604a8b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### L2 distance to quantify change",
   "id": "c4564d6afca90537"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "og_s = partition_og_shap_values[same_idxs]\n",
    "random_s = partition_random_shap_values[same_idxs]\n",
    "noise_s = partition_og_shap_noisy_samples_values[same_idxs]\n",
    "\n",
    "randomised_l2_df = helpers.similarity_metrics.make_l2_distance_per_label_df(\n",
    "    eurosat_val_ds.classes, og_s, random_s, normalise=True)\n",
    "continuity_l2_df = helpers.similarity_metrics.make_l2_distance_per_label_df(\n",
    "    eurosat_val_ds.classes, og_s, noise_s, normalise=True)\n",
    "randomised_l2_df.join(continuity_l2_df, lsuffix=\" (to randomised)\", rsuffix=\" (to noisy)\").plot(kind=\"bar\")"
   ],
   "id": "21a20c1e5ea5347f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Not normalised version (same explanation type)",
   "id": "fadae0bfc305e926"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "l2_to_random_no_norm_df = helpers.similarity_metrics.make_l2_distance_per_label_df(\n",
    "    eurosat_val_ds.classes, og_s, random_s, normalise=False)\n",
    "l2_to_noisy_no_norm_df = helpers.similarity_metrics.make_l2_distance_per_label_df(\n",
    "    eurosat_val_ds.classes, og_s, noise_s, normalise=False)\n",
    "\n",
    "l2_to_random_no_norm_df.join(l2_to_noisy_no_norm_df, lsuffix=\" (to randomised)\", rsuffix=\" (to noisy)\").plot(kind=\"bar\")"
   ],
   "id": "da08d0ec50637082"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Distance of prediction labels only",
   "id": "4fd4b20a12705091"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "original_labels = pred_change_df[pred_change_df['original_pred'] == pred_change_df['perturbed_pred']][\n",
    "    'original_pred'].tolist()\n",
    "extracted_noisy = partition_og_shap_noisy_samples_values[same_idxs, ..., original_labels][..., np.newaxis]\n",
    "extracted_og = partition_og_shap_values[same_idxs, ..., original_labels][..., np.newaxis]\n",
    "extracted_random = partition_random_shap_values[same_idxs, ..., original_labels][..., np.newaxis]\n",
    "extracted_noisy.shape, extracted_og.shape"
   ],
   "id": "296f93061d989ed3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "helpers.similarity_metrics.make_l2_distance_per_label_df(\n",
    "    [\"Prediction\"], extracted_og, extracted_noisy, normalise=False)"
   ],
   "id": "b6ef6482216ed8f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "helpers.similarity_metrics.make_l2_distance_per_label_df(\n",
    "    [\"Prediction\"], extracted_og, extracted_random, normalise=False)"
   ],
   "id": "946ce906f258fa63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Compare rankings?",
   "id": "4b46863f432ae209"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "og_ranked = helpers.utils.rank_pixel_importance(extracted_og[:, :, :, 0].sum(-1))\n",
    "noisy_ranked = helpers.utils.rank_pixel_importance(extracted_noisy[:, :, :, 0].sum(-1))"
   ],
   "id": "b827aad9f571719b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.matshow(np.hstack([og_ranked[0], np.zeros((224, 50)), noisy_ranked[0]]), cmap=\"plasma_r\")",
   "id": "348225466a56b0b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "average_scc = helpers.similarity_metrics.spearman_rank(\n",
    "    og_ranked, noisy_ranked, show_plot=True\n",
    ").mean()"
   ],
   "id": "318ea472839b9f85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.matshow(np.hstack([og_ranked[2], np.zeros((224, 10)), noisy_ranked[2]]), cmap=\"plasma_r\")",
   "id": "5dc17132cdd961ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A higher SCC statistic indicates that the rankings agree with each other more, i.e. that the relative ranking of pixels didn't change from original image to perturbed version.",
   "id": "7c89b418945d121e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Average SCC (where model prediction hasn't changed) (↑, 1 best): {average_scc:.4f}\")",
   "id": "7b3ebdeaa2fb1899"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### Compared to uncorrelated\n",
    "\n",
    "As a comparison, for e.g. index 1 image, the prediction changed from class 7 to class 0 so the rankings are very unrelated to each other."
   ],
   "id": "dd3b238cd4f9b2f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "temp1 = partition_og_shap_values[[1, 4], ..., [7, 3]]\n",
    "temp2 = partition_og_shap_noisy_samples_values[[1, 4], ..., [0, 7]]\n",
    "temp1.shape"
   ],
   "id": "a07e913cb8502ba3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "temp1_rank = helpers.utils.rank_pixel_importance(temp1.sum(-1))[0].flatten()\n",
    "temp2_rank = helpers.utils.rank_pixel_importance(temp2.sum(-1))[0].flatten()\n",
    "\n",
    "plt.title(f\"SCC={spearmanr(temp1_rank, temp2_rank).statistic:.3f}\")\n",
    "plt.scatter(temp1_rank, temp2_rank)\n",
    "plt.plot(range(temp1_rank.max()), \"r--\", label=\"SCC$=+1$\")\n",
    "plt.plot(range(temp1_rank.max(), 0, -1), \"y--\", label=\"SCC$=-1$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "82cde8f3d165b3b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Compare top-k intersection?",
   "id": "aa8d2407823c9ff5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "intersections = helpers.similarity_metrics.top_k_intersection(og_ranked, noisy_ranked, 5000)",
   "id": "98794015d9db16be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print([f\"{i:.4f}\" for i in intersections])\n",
    "print(f\"Average intersection percentage of top {5000} \"\n",
    "      f\"(where model prediction hasn't changed) (↑, 1 best): {intersections.mean():.4f}\")"
   ],
   "id": "8df766dc855016ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### SSIM",
   "id": "9fc0dc438fd5e9ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ssims = helpers.similarity_metrics.structural_similarity(og_ranked, noisy_ranked)",
   "id": "e011ebd8efcc1b0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Average SSIM value betweens explanations (↑, 1 best): {ssims.mean():.4f}\")",
   "id": "40b23c5e6f414967"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Return all these metrics when formalising - allows choice by end user",
   "id": "158dd7bf6037e08b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Contrastivity: Adversarial Attack",
   "id": "aca77b4186f39a9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Generate Adversarial Examples",
   "id": "7ad03cf84579f1e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fmodel = foolbox.PyTorchModel(resnet50, bounds=(-1, 1))",
   "id": "8634e58c80e0f210"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "attack = foolbox.attacks.LinfDeepFoolAttack()\n",
    "# fooling_criteria = foolbox.criteria.TargetedMisclassification(((torch.stack(true_labels)+1)%num_eurosat_classes).to(device))\n",
    "fooling_criteria = foolbox.criteria.Misclassification(torch.stack(true_labels).to(device))\n",
    "# epsilons = np.linspace(0.01, 1, num=20)\n",
    "adversarial_imgs, clipped, is_adv = attack(fmodel, imgs_to_explain, fooling_criteria, epsilons=0.01)\n",
    "helpers.plotting.show_image(adversarial_imgs)"
   ],
   "id": "de214cc596b7dc50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "preds = resnet50(imgs_to_explain)\n",
    "preds = torch.softmax(preds, dim=-1).cpu().detach().numpy()\n",
    "_, axs = plt.subplots(1, len(idxs_to_explain), figsize=(2 * len(idxs_to_explain), 2))\n",
    "for i in range(len(idxs_to_explain)):\n",
    "    ax: plt.Axes = axs[i]\n",
    "    ax.bar(eurosat_val_ds.classes, preds[i])\n",
    "    # rotate x ticks for axis\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.set_ylim([0, 1])"
   ],
   "id": "d9e95c758be1feef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "preds = resnet50(adversarial_imgs)\n",
    "preds = torch.softmax(preds, dim=-1).cpu().detach().numpy()\n",
    "_, axs = plt.subplots(1, len(idxs_to_explain), figsize=(2 * len(idxs_to_explain), 2))\n",
    "for i in range(len(idxs_to_explain)):\n",
    "    ax: plt.Axes = axs[i]\n",
    "    ax.bar(eurosat_val_ds.classes, preds[i])\n",
    "    # rotate x ticks for axis\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.set_ylim([0, 1])"
   ],
   "id": "2393d1e3d4a957e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Generate explanations on adversarial examples",
   "id": "34ad9d3cafa187e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np01_adversarial_samples = einops.rearrange((adversarial_imgs + 1) / 2, \"b c h w -> b h w c\").cpu().numpy()\n",
    "partition_og_shap_adversarial_samples = og_partition_e(\n",
    "    np01_adversarial_samples,\n",
    "    max_evals=10000,\n",
    "    batch_size=64,\n",
    ")"
   ],
   "id": "d204ed668665884a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "partition_og_shap_adversarial_samples_values = partition_og_shap_adversarial_samples.values\n",
    "# np.savez_compressed(output_path / f\"resnet50_adv_shap_vals.npz\",\n",
    "#                     partition_og_shap_noisy_samples_values=partition_og_shap_adversarial_samples_values,\n",
    "#                     images=np01_adversarial_samples,\n",
    "#                     )"
   ],
   "id": "365fa6f104123fbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with np.load(output_path / f\"resnet50_adv_shap_vals.npz\") as data:\n",
    "    partition_og_shap_noisy_samples_values = data[\"partition_og_shap_noisy_samples_values\"]\n",
    "    np01_adversarial_samples = data[\"images\"]\n",
    "    adversarial_imgs = torch.from_numpy(einops.rearrange((np01_adversarial_samples * 2) - 1, \"b h w c -> b c h w\"))"
   ],
   "id": "b09a818832261702"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shap.image_plot(\n",
    "    shap_values=[val for val in np.moveaxis(partition_og_shap_adversarial_samples_values, -1, 0)],\n",
    "    pixel_values=((np01_adversarial_samples + 1) / 2),\n",
    "    labels=np.tile([x[:5] for x in eurosat_val_ds.classes], (np01_adversarial_samples.shape[0], 1)),\n",
    "    true_labels=[f'{eurosat_val_ds.classes[int(i)][:5]}' for i in true_labels],\n",
    "    hspace=\"auto\",\n",
    "    show=False,\n",
    ")\n",
    "print(\"SHAP values for adversarial image\")"
   ],
   "id": "eb6b0169464babf8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Compare explanations and generate metrics",
   "id": "c84fb5a1eba5b52f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "original_idxs = resnet50(imgs_to_explain.to(device)).softmax(-1).argmax(-1).cpu().detach().numpy()\n",
    "attacked_idxs = resnet50(adversarial_imgs.to(device)).softmax(-1).argmax(-1).cpu().detach().numpy()\n",
    "original_idxs, attacked_idxs"
   ],
   "id": "5557965549873dc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "og_explanations = partition_og_shap_values[range(len(original_idxs)), ..., original_idxs]\n",
    "adv_explanations = partition_og_shap_adversarial_samples_values[range(\n",
    "    len(attacked_idxs)), ..., attacked_idxs]  # for SHAP values, the selected explanations changes since the output class has changed\n",
    "og_explanations.shape"
   ],
   "id": "91023e58a915d2b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "og_rankings = helpers.utils.rank_pixel_importance(og_explanations.sum(-1))\n",
    "adv_rankings = helpers.utils.rank_pixel_importance(adv_explanations.sum(-1))"
   ],
   "id": "2dc787c5745b1856"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.matshow(np.hstack([og_rankings[-1], adv_rankings[-1]]), cmap=\"plasma_r\")",
   "id": "3c5501e4793dbb56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "helpers.similarity_metrics.spearman_rank(og_rankings,\n",
    "                                         adv_rankings)  # lower better now - we want the explanations to have changed a lot"
   ],
   "id": "a1beca61b1b439d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "helpers.similarity_metrics.top_k_intersection(og_rankings, adv_rankings)  # lower better",
   "id": "ce45802adb50ec57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "helpers.similarity_metrics.structural_similarity(og_rankings, adv_rankings)  # lower better",
   "id": "803a318967fff69b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Compactness",
   "id": "ab4951bc62d64109"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "og_shap_abs = np.abs(\n",
    "    og_explanations.sum(-1))  # sum over colour channels; negative parts of the explanation also contribute to clutter\n",
    "og_shap_abs /= og_shap_abs.max(axis=(1, 2), keepdims=True)  # normalise each image/row\n",
    "og_shap_abs.shape"
   ],
   "id": "f1961e9f2a66e74f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.matshow(og_shap_abs[-1], cmap=\"plasma\")",
   "id": "a95dad0316da7b6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "over_half_activated = np.sum(og_shap_abs > 0.5, axis=(1, 2)) / og_shap_abs[0].size\n",
    "over_half_activated"
   ],
   "id": "72f0f2fa8f418f1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "over_q3_activated = np.sum(og_shap_abs > 0.75, axis=(1, 2)) / og_shap_abs[0].size\n",
    "over_q3_activated"
   ],
   "id": "92b8380eb19fed5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "helpers.evaluate_xai.compactness(og_shap_abs, 0.75)",
   "id": "81f2d73474183a34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dfb9421d2dd39163"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
